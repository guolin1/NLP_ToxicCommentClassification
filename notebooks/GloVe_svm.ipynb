{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599693811633",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA MANIPULATION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## NLTK HELPER FUNCTIONS\n",
    "from nltk import word_tokenize\n",
    "from nltk import punkt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "## CLASSIFICATION\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(106912,) (52659,)\n"
    }
   ],
   "source": [
    "## LOAD, CLEAN, SPLIT DATA\n",
    "data = pd.read_csv('../data/train.csv')\n",
    "data['comment_text'].fillna(\"unknown\", inplace=True)\n",
    "train, valid = train_test_split(data, random_state=42, test_size=0.33, shuffle=True)\n",
    "X_train = train['comment_text']\n",
    "X_valid = valid['comment_text']\n",
    "print(X_train.shape, X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(data.columns[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Extracted 400000 word vectors\n"
    }
   ],
   "source": [
    "## BUILD GLOVE EMBEDDINGS DICTIONARY\n",
    "embeddings_dict = dict()\n",
    "f = open(r'../data/glove.6B.300d.txt', encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_dict[word] = vec\n",
    "f.close()\n",
    "print('Extracted {} word vectors'.format(len(embeddings_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTION THAT CONVERTS COMMENTS TO VEC\n",
    "stop_words = stopwords.words('english')\n",
    "def comment2vec(s):\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_dict[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONVERT COMMENTS TO VEC\n",
    "X_train_glove = X_train.apply(comment2vec)\n",
    "X_valid_glove = X_valid.apply(comment2vec)\n",
    "X_train_glove = np.stack(X_train_glove.values, axis=0)\n",
    "X_valid_glove = np.stack(X_valid_glove.values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[-0.01483988,  0.0263314 , -0.0679364 , ..., -0.05361094,\n        -0.02683323,  0.02075227],\n       [-0.02131595,  0.01925481, -0.01717966, ...,  0.00667108,\n        -0.01023916,  0.00571783],\n       [-0.04826125, -0.01935945, -0.03799327, ...,  0.02294068,\n        -0.02901444, -0.04871771],\n       ...,\n       [ 0.00313657,  0.02736013, -0.01489128, ..., -0.03033283,\n         0.0095365 ,  0.0128214 ],\n       [-0.00935701, -0.01064557,  0.00927812, ...,  0.04194981,\n        -0.05753804, -0.00346779],\n       [-0.02948582,  0.0032135 , -0.03273927, ..., -0.0174906 ,\n         0.00701386,  0.04236213]])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X_train_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Validation accuracy for toxic comments is 0.93, with precision score of 0.81 and recall score of 0.40\nValidation accuracy for severe_toxic comments is 0.99, with precision score of 0.50 and recall score of 0.00\nValidation accuracy for obscene comments is 0.96, with precision score of 0.81 and recall score of 0.39\nValidation accuracy for threat comments is 1.00, with precision score of 0.00 and recall score of 0.00\nValidation accuracy for insult comments is 0.96, with precision score of 0.76 and recall score of 0.32\nValidation accuracy for identity_hate comments is 0.99, with precision score of 1.00 and recall score of 0.01\n"
    }
   ],
   "source": [
    "## CREATE A MODEL FOR EACH CATEGORY\n",
    "for label in labels:\n",
    "    # Create and fit model\n",
    "    m = LinearSVC(class_weight='balanced')  # Balanced class weights [n_samples / n_classes * np.bincount(y)]\n",
    "    m.fit(X_train_glove, train[label].values)\n",
    "    # Get predictions\n",
    "    preds = m.predict(X_valid_glove)\n",
    "    # Evaluate predictions\n",
    "    print('Validation accuracy for {0} comments is {1:.2f}, with precision score of {2:.2f} and recall score of {3:.2f}'.format(\n",
    "                                    label, \n",
    "                                    accuracy_score(valid[label], preds), \n",
    "                                    precision_score(valid[label], preds), \n",
    "                                    recall_score(valid[label], preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}