{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA MANIPULATION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## NLP HELPER FUNS\n",
    "import nltk\n",
    "\n",
    "## SKLEARN FUNS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(106912,) (52659,)\n"
    }
   ],
   "source": [
    "## LOAD, CLEAN, SPLIT DATA\n",
    "data = pd.read_csv('../data/train.csv')\n",
    "data['comment_text'].fillna(\"unknown\", inplace=True)\n",
    "train, valid = train_test_split(data, random_state=42, test_size=0.33, shuffle=True)\n",
    "X_train = train['comment_text']\n",
    "X_valid = valid['comment_text']\n",
    "print(X_train.shape, X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET LABELS FOR EACH CATEGORY \n",
    "labels = list(data.columns[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Extracted 400000 word vectors\n"
    }
   ],
   "source": [
    "## BUILD GLOVE EMBEDDINGS DICTIONARY\n",
    "embeddings_dict = dict()\n",
    "f = open(r'../data/glove.6B.300d.txt', encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_dict[word] = vec\n",
    "f.close()\n",
    "print('Extracted {} word vectors'.format(len(embeddings_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SKLEARN COMPATIBLE GLOVE VECTORIZER TRANSFORMER \n",
    "class gloveVectorizer(object):\n",
    "    def __init__(self, embeddings_dict):\n",
    "        self.embeddings_dict = embeddings_dict\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(embeddings_dict[next(iter(embeddings_dict))])\n",
    "        # NLTK helper functions\n",
    "        self.stop_words = nltk.corpus.stopwords.words('english')\n",
    "        self.lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "        self.tokenizer = nltk.word_tokenize\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def sentence2vec(self, s):\n",
    "        '''\n",
    "        Input:\n",
    "        Sentence string\n",
    "\n",
    "        Transformations:\n",
    "        Lower case -> Tokenize -> Remove stop words ->\n",
    "        Remove non-words -> Lemmatize -> Get vector for each word ->\n",
    "        Average vectors\n",
    "\n",
    "        Output:\n",
    "        Vector for sentence\n",
    "        '''\n",
    "        words = str(s).lower()\n",
    "        words = self.tokenizer(words)\n",
    "        words = [w for w in words if not w in self.stop_words]\n",
    "        words = [w for w in words if w.isalpha()]\n",
    "        words = [self.lemmatizer.lemmatize(w) for w in words]\n",
    "        M = []\n",
    "        for w in words:\n",
    "            try:\n",
    "                M.append(self.embeddings_dict[w])\n",
    "            except:\n",
    "                continue\n",
    "        M = np.array(M)\n",
    "        v = M.mean(axis=0)\n",
    "        if type(v) != np.ndarray:\n",
    "            return np.zeros(self.dim)\n",
    "        return v # / np.sqrt((v ** 2).sum())\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.apply(self.sentence2vec)\n",
    "        return np.stack(X.values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Validation accuracy for toxic comments is 0.89, with precision score of 0.46 and recall score of 0.83\nValidation accuracy for severe_toxic comments is 0.95, with precision score of 0.14 and recall score of 0.87\nValidation accuracy for obscene comments is 0.92, with precision score of 0.38 and recall score of 0.84\nValidation accuracy for threat comments is 0.96, with precision score of 0.05 and recall score of 0.78\nValidation accuracy for insult comments is 0.91, with precision score of 0.35 and recall score of 0.85\nValidation accuracy for identity_hate comments is 0.92, with precision score of 0.09 and recall score of 0.86\n"
    }
   ],
   "source": [
    "## SKLEARN PIPELINE\n",
    "pipeline = Pipeline([('GloVe Vectorizer', gloveVectorizer(embeddings_dict)), \n",
    "                     ('Linear SVM', LinearSVC(class_weight='balanced'))])\n",
    "\n",
    "## CREATE A MODEL FOR EACH CATEGORY\n",
    "for label in labels:\n",
    "    # Create and fit pipeline\n",
    "    pipeline.fit(X_train, train[label].values)\n",
    "    # Get predictions\n",
    "    preds = pipeline.predict(X_valid)\n",
    "    # Evaluate predictions\n",
    "    print('Validation accuracy for {0} comments is {1:.2f}, with precision score of {2:.2f} and recall score of {3:.2f}'.format(\n",
    "                                    label, \n",
    "                                    accuracy_score(valid[label], preds), \n",
    "                                    precision_score(valid[label], preds), \n",
    "                                    recall_score(valid[label], preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}