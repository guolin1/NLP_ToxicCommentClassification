{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600309848125",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA MANIPULATION\n",
    "import numpy as np, pandas as pd\n",
    "import pickle\n",
    "\n",
    "## CLASSIFICATION\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "source": [
    "### Load preprocessed data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/preprocessed.pkl','rb')\n",
    "train, valid = pickle.load(f)\n",
    "labels = train.columns[2:]\n",
    "ys_train = train[labels]\n",
    "ys_valid = valid[labels]\n",
    "\n",
    "## COMBINE TOXIC CATEGORIES\n",
    "y_train = ys_train.sum(axis=1)\n",
    "y_valid = ys_valid.sum(axis=1)\n",
    "y_train.loc[y_train>1] = 1\n",
    "y_valid.loc[y_valid>1] = 1"
   ]
  },
  {
   "source": [
    "### Build embeddings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Extracted 3000000 word vectors\n"
    }
   ],
   "source": [
    "## BUILD WORD2VEC EMBEDDINGS DICTIONARY\n",
    "embeddings_dict = dict()\n",
    "f = open(r'../data/GoogleNews-vectors-negative300.txt',encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_dict[word] = vec\n",
    "f.close()\n",
    "print('Extracted {} word vectors'.format(len(embeddings_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SKLEARN COMPATIBLE WORD2Vec VECTORIZER TRANSFORMER \n",
    "class w2cVectorizer(object):\n",
    "    def __init__(self, embeddings_dict):\n",
    "        self.embeddings_dict = embeddings_dict\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        # self.dim = len(embeddings_dict[next(iter(embeddings_dict))])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def sentence2vec(self, s):\n",
    "        '''\n",
    "        Input:\n",
    "        Sentence string\n",
    "\n",
    "        Transformations:\n",
    "        Get vector for each word -> Average vectors\n",
    "\n",
    "        Output:\n",
    "        Vector for sentence\n",
    "        '''\n",
    "        words = s.split()\n",
    "        M = []\n",
    "        for w in words:\n",
    "            try:\n",
    "                M.append(self.embeddings_dict[w])\n",
    "            except:\n",
    "                continue\n",
    "        M = np.array(M)\n",
    "        v = M.mean(axis=0)\n",
    "        if type(v) != np.ndarray:\n",
    "            # return np.zeros(self.dim)\n",
    "            return np.zeros(300)\n",
    "        return v # / np.sqrt((v ** 2).sum())\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.apply(self.sentence2vec)\n",
    "        return np.stack(X.values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2c = w2cVectorizer(embeddings_dict)\n",
    "X_train = w2c.transform(train['comment_text'])\n",
    "X_valid = w2c.transform(valid['comment_text'])"
   ]
  },
  {
   "source": [
    "### Loop through models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Logistic Regression Results for Toxic_Combined comments: Accuracy - 0.91; Precision - 0.52; Recall - 0.87; F1 - 0.65\nSVM Results for Toxic_Combined comments: Accuracy - 0.91; Precision - 0.53; Recall - 0.86; F1 - 0.66\nXGBoost Results for Toxic_Combined comments: Accuracy - 0.94; Precision - 0.68; Recall - 0.77; F1 - 0.72\n"
    }
   ],
   "source": [
    "## CREATE RESULTS TABLE\n",
    "results = pd.DataFrame(columns=['Label', 'Accuracy', 'Recall', 'Precision', 'F1', 'Vectorizer', 'model'])\n",
    "\n",
    "## CREATE MODELS\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='saga',class_weight='balanced'),\n",
    "    'SVM': LinearSVC(class_weight='balanced'),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100,\n",
    "                        scale_pos_weight= sum(y_train==0) / sum(y_train==1),\n",
    "                        n_jobs=-1)}\n",
    "                      \n",
    "## LOOP THROUGH MODELS\n",
    "for m_label, model in models.items():\n",
    "        m = clone(model) \n",
    "\n",
    "        # Fit model\n",
    "        m.fit(X_train, y_train)\n",
    "        \n",
    "        # Get predictions\n",
    "        preds = m.predict(X_valid)\n",
    "\n",
    "        # Evaluate predictions\n",
    "        acc, prec, recall, f1 = (accuracy_score(y_valid, preds), \n",
    "                                precision_score(y_valid, preds), \n",
    "                                recall_score(y_valid, preds), \n",
    "                                f1_score(y_valid, preds))\n",
    "        \n",
    "        # Save results to dataframe\n",
    "        results = results.append({'Label': 'Toxic_Combined',\n",
    "                                'Accuracy':acc,\n",
    "                                'Recall':recall,\n",
    "                                'Precision':prec,\n",
    "                                'F1':f1,\n",
    "                                'Vectorizer':'word2vec',\n",
    "                                'model': m_label}, \n",
    "                                ignore_index = True)\n",
    "        \n",
    "        # print results\n",
    "        print('{0} Results for {1} comments: Accuracy - {2:.2f}; Precision - {3:.2f}; Recall - {4:.2f}; F1 - {5:.2f}'.format(\n",
    "                                        m_label,\n",
    "                                        'Toxic_Combined', \n",
    "                                        acc, \n",
    "                                        prec, \n",
    "                                        recall,\n",
    "                                        f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            Label  Accuracy    Recall  Precision        F1 Vectorizer  \\\n0  Toxic_Combined  0.905277  0.866568   0.522809  0.652162   word2vec   \n1  Toxic_Combined  0.907024  0.861935   0.528403  0.655163   word2vec   \n2  Toxic_Combined  0.939744  0.765938   0.683932  0.722616   word2vec   \n\n                 model  \n0  Logistic Regression  \n1                  SVM  \n2              XGBoost  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n      <th>Vectorizer</th>\n      <th>model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Toxic_Combined</td>\n      <td>0.905277</td>\n      <td>0.866568</td>\n      <td>0.522809</td>\n      <td>0.652162</td>\n      <td>word2vec</td>\n      <td>Logistic Regression</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Toxic_Combined</td>\n      <td>0.907024</td>\n      <td>0.861935</td>\n      <td>0.528403</td>\n      <td>0.655163</td>\n      <td>word2vec</td>\n      <td>SVM</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Toxic_Combined</td>\n      <td>0.939744</td>\n      <td>0.765938</td>\n      <td>0.683932</td>\n      <td>0.722616</td>\n      <td>word2vec</td>\n      <td>XGBoost</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('../artifacts/simple/word2vec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}