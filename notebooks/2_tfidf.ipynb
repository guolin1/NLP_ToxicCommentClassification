{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA MANIPULATION\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "## TF-IDF VECTORIZER\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "## CLASSIFICATION\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD PREPROCESSED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/preprocessed.pkl','rb')\n",
    "train, valid = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE BAG OF WORDS (TF-IDF) TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2),\n",
    "                        min_df=3, \n",
    "                        max_df=0.9, \n",
    "                        strip_accents='unicode', \n",
    "                        use_idf=1,\n",
    "                        smooth_idf=1, \n",
    "                        sublinear_tf=1)\n",
    "\n",
    "X_train = tfidf.fit_transform(train['comment_text'])      # vectorized train x\n",
    "X_valid = tfidf.transform(valid['comment_text'])          # vectorized valid x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STRONG BASELINE (LINEAR MODEL): NB-SVM\n",
    "- based on Wang & Manning, 2012 (https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf)\n",
    "- A SVM model (liblinear) that takes transformed features using Naive Bayes' log-count ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Results for toxic comments: Accuracy - 0.96; Precision - 0.83; Recall - 0.75; F1 - 0.79\nResults for severe_toxic comments: Accuracy - 0.99; Precision - 0.39; Recall - 0.34; F1 - 0.37\nResults for obscene comments: Accuracy - 0.98; Precision - 0.84; Recall - 0.76; F1 - 0.80\nResults for threat comments: Accuracy - 1.00; Precision - 0.68; Recall - 0.38; F1 - 0.48\nResults for insult comments: Accuracy - 0.97; Precision - 0.75; Recall - 0.65; F1 - 0.70\nResults for identity_hate comments: Accuracy - 0.99; Precision - 0.56; Recall - 0.32; F1 - 0.40\n"
    }
   ],
   "source": [
    "## NB-SVM MODEL\n",
    "def NB_SVM(x,y):\n",
    "    y = y.values\n",
    "    sum_1 = x[y==1].sum(axis=0)+1           # Feature Sum for Class 1\n",
    "    p_1 = (sum_1) / ((y==1).sum())          # Convert to ratio of feature in class 1 - p(f|1)\n",
    "\n",
    "    sum_0 = x[y==0].sum(axis=0)+1           # Feature Sum for Class 0\n",
    "    p_0 = (sum_0) / ((y==0).sum())          # Convert to ratio of feature in class 0 - p(f|0) \n",
    "\n",
    "    r = np.log(p_1/p_0)                     # Compute log ratios (the transformation matrix)\n",
    "    x_nb = x.multiply(r)                    # Obtain NB feature\n",
    "    \n",
    "    m = LinearSVC(class_weight='balanced')  # Balanced class weights [n_samples / n_classes * np.bincount(y)]\n",
    "    m.fit(x_nb,y)                           # Fit model\n",
    "    return m , r                            # return fitted model & transformation matrix (need for X_valid / X_test)\n",
    "\n",
    "labels = train.columns[2:]                  # Grab labels\n",
    "\n",
    "## CREATE A MODEL FOR EACH CATEGORY\n",
    "for label in labels:\n",
    "    # Get model and transformation matrix for category\n",
    "    m,r = NB_SVM(X_train, train[label])\n",
    "    # Get predictions\n",
    "    preds = m.predict(X_valid.multiply(r))\n",
    "    # Evaluate predictions\n",
    "    print('Results for {0} comments: Accuracy - {1:.2f}; Precision - {2:.2f}; Recall - {3:.2f}; F1 - {4:.2f}'.format(\n",
    "                                    label, \n",
    "                                    accuracy_score(valid[label], preds), \n",
    "                                    precision_score(valid[label], preds), \n",
    "                                    recall_score(valid[label], preds),\n",
    "                                    f1_score(valid[label], preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Results for toxic comments: Accuracy - 0.95; Precision - 0.67; Recall - 0.86; F1 - 0.75\nResults for severe_toxic comments: Accuracy - 0.93; Precision - 0.12; Recall - 0.98; F1 - 0.22\nResults for obscene comments: Accuracy - 0.98; Precision - 0.75; Recall - 0.87; F1 - 0.81\nResults for threat comments: Accuracy - 0.82; Precision - 0.02; Recall - 0.96; F1 - 0.03\nResults for insult comments: Accuracy - 0.89; Precision - 0.32; Recall - 0.96; F1 - 0.48\nResults for identity_hate comments: Accuracy - 0.42; Precision - 0.02; Recall - 1.00; F1 - 0.03\n"
    }
   ],
   "source": [
    "for label in labels:\n",
    "    # Create & Fit model\n",
    "    m = LogisticRegression(solver='saga',class_weight='balanced')\n",
    "    m.fit(X_train, train[label])\n",
    "    # Get predictions\n",
    "    preds = m.predict(X_valid)\n",
    "    # Evaluate predictions\n",
    "    print('Results for {0} comments: Accuracy - {1:.2f}; Precision - {2:.2f}; Recall - {3:.2f}; F1 - {4:.2f}'.format(\n",
    "                                    label, \n",
    "                                    accuracy_score(valid[label], preds), \n",
    "                                    precision_score(valid[label], preds), \n",
    "                                    recall_score(valid[label], preds),\n",
    "                                    f1_score(valid[label], preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Results for toxic comments: Accuracy - 0.96; Precision - 0.79; Recall - 0.78; F1 - 0.79\nResults for severe_toxic comments: Accuracy - 0.99; Precision - 0.39; Recall - 0.52; F1 - 0.45\nResults for obscene comments: Accuracy - 0.98; Precision - 0.82; Recall - 0.81; F1 - 0.82\nResults for threat comments: Accuracy - 1.00; Precision - 0.58; Recall - 0.47; F1 - 0.52\nResults for insult comments: Accuracy - 0.97; Precision - 0.71; Recall - 0.75; F1 - 0.73\nResults for identity_hate comments: Accuracy - 0.99; Precision - 0.51; Recall - 0.47; F1 - 0.49\n"
    }
   ],
   "source": [
    "for label in labels:\n",
    "    # Create & Fit model\n",
    "    m = LinearSVC(class_weight='balanced')\n",
    "    m.fit(X_train, train[label])\n",
    "    # Get predictions\n",
    "    preds = m.predict(X_valid)\n",
    "    # Evaluate predictions\n",
    "    print('Results for {0} comments: Accuracy - {1:.2f}; Precision - {2:.2f}; Recall - {3:.2f}; F1 - {4:.2f}'.format(\n",
    "                                    label, \n",
    "                                    accuracy_score(valid[label], preds), \n",
    "                                    precision_score(valid[label], preds), \n",
    "                                    recall_score(valid[label], preds),\n",
    "                                    f1_score(valid[label], preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Results for toxic comments: Accuracy - 0.94; Precision - 0.63; Recall - 0.82; F1 - 0.71\nResults for severe_toxic comments: Accuracy - 0.98; Precision - 0.30; Recall - 0.74; F1 - 0.43\nResults for obscene comments: Accuracy - 0.98; Precision - 0.73; Recall - 0.88; F1 - 0.80\nResults for threat comments: Accuracy - 1.00; Precision - 0.33; Recall - 0.52; F1 - 0.41\nResults for insult comments: Accuracy - 0.96; Precision - 0.54; Recall - 0.84; F1 - 0.66\nResults for identity_hate comments: Accuracy - 0.98; Precision - 0.25; Recall - 0.65; F1 - 0.36\n"
    }
   ],
   "source": [
    "for label in labels:\n",
    "    # Create & Fit model\n",
    "    m = XGBClassifier(n_estimators=100,\n",
    "                      scale_pos_weight= sum(train[label]==0) / sum(train[label]==1),\n",
    "                      n_jobs=-1)\n",
    "    m.fit(X_train, train[label])\n",
    "    # Get predictions\n",
    "    preds = m.predict(X_valid)\n",
    "    # Evaluate predictions\n",
    "    print('Results for {0} comments: Accuracy - {1:.2f}; Precision - {2:.2f}; Recall - {3:.2f}; F1 - {4:.2f}'.format(\n",
    "                                    label, \n",
    "                                    accuracy_score(valid[label], preds), \n",
    "                                    precision_score(valid[label], preds), \n",
    "                                    recall_score(valid[label], preds),\n",
    "                                    f1_score(valid[label], preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}