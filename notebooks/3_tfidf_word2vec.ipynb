{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA MANIPULATION\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "## TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "## CLASSIFICATION\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "source": [
    "### Load preprocessed data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/preprocessed.pkl','rb')\n",
    "train, valid = pickle.load(f)\n",
    "labels = train.columns[2:]"
   ]
  },
  {
   "source": [
    "### TF-IDF weighted Word2Vec vectorizer\n",
    "- TF-IDF down-weighs frequent terms and up-weighs rare terms, which helps identify indicators for toxic comments (i.e., they're less common)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BUILD WORD2VEC EMBEDDINGS DICTIONARY\n",
    "embeddings_dict = dict()\n",
    "f = open(r'../data/GoogleNews-vectors-negative300.txt',encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_dict[word] = vec\n",
    "f.close()\n",
    "print('Extracted {} word vectors'.format(len(embeddings_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SKLEARN COMPATIBLE TF-IDF-Word2Vec VECTORIZER TRANSFORMER \n",
    "class tfidf_w2c(object):\n",
    "    def __init__(self, embeddings_dict):\n",
    "        # Glove Embeddings Dictionary\n",
    "        self.embeddings_dict = embeddings_dict\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(embeddings_dict[next(iter(embeddings_dict))])\n",
    "        # Initialize TF-IDF\n",
    "        self.tfidf = TfidfVectorizer(min_df=3,\n",
    "                                    token_pattern = '\\S+', # preserve each word in preprocessed text\n",
    "                                    max_df=0.9, \n",
    "                                    strip_accents='unicode',\n",
    "                                    sublinear_tf=1)\n",
    "        # TF-IDF weights dictionary\n",
    "        self.weights_dict = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        fit tfidf and create weight dictionary\n",
    "        credit: github.com/nadbordrozd\n",
    "        '''\n",
    "        self.tfidf.fit(X)\n",
    "        # if a word doesn't exist, it needs to be considered as \n",
    "        # infrequent as the most infrequent known words, i.e., \n",
    "        # it should have the highest known idf value.\n",
    "        max_idf = max(self.tfidf.idf_)\n",
    "        self.weights_dict = defaultdict(\n",
    "            lambda: max_idf, \n",
    "            [(w, self.tfidf.idf_[i]) for w, i in self.tfidf.vocabulary_.items()])\n",
    "        return self\n",
    "    \n",
    "    def sentence2vec(self, s):\n",
    "        '''\n",
    "        Input:\n",
    "        Sentence string\n",
    "\n",
    "        Transformations:\n",
    "        Get vector for each word -> \n",
    "        weigh the vector by idf value ->\n",
    "        Average vectors\n",
    "\n",
    "        Output:\n",
    "        Vector for sentence\n",
    "        '''\n",
    "        words = s.split()\n",
    "        M = []\n",
    "        for w in words:\n",
    "            try:\n",
    "                M.append(self.embeddings_dict[w] * self.weights_dict[w])\n",
    "            except:\n",
    "                continue\n",
    "        M = np.array(M)\n",
    "        v = M.mean(axis=0)\n",
    "        if type(v) != np.ndarray:\n",
    "            return np.zeros(self.dim)\n",
    "        return v # / np.sqrt((v ** 2).sum())\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.apply(self.sentence2vec)\n",
    "        return np.stack(X.values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = tfidf_w2c(embeddings_dict)\n",
    "X_train = vec.fit(train['comment_text'], train[labels[0]]).transform(train['comment_text'])\n",
    "X_valid = vec.transform(valid['comment_text'])"
   ]
  },
  {
   "source": [
    "### SVM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE A MODEL FOR EACH CATEGORY\n",
    "for label in labels:\n",
    "    # Create and fit model\n",
    "    m = LinearSVC(class_weight='balanced')\n",
    "    m.fit(X_train, train[label].values)\n",
    "    # Get predictions\n",
    "    preds = m.predict(X_valid)\n",
    "    # Evaluate predictions\n",
    "    print('Results for {0} comments: Accuracy - {1:.2f}; Precision - {2:.2f}; Recall - {3:.2f}; F1 - {4:.2f}'.format(\n",
    "                                    label, \n",
    "                                    accuracy_score(valid[label], preds), \n",
    "                                    precision_score(valid[label], preds), \n",
    "                                    recall_score(valid[label], preds),\n",
    "                                    f1_score(valid[label], preds)))"
   ]
  },
  {
   "source": [
    "### Logistic regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE A MODEL FOR EACH CATEGORY\n",
    "for label in labels:\n",
    "    # Create & Fit model\n",
    "    m = LogisticRegression(solver='saga',class_weight='balanced')\n",
    "    m.fit(X_train, train[label])\n",
    "    # Get predictions\n",
    "    preds = m.predict(X_valid)\n",
    "    # Evaluate predictions\n",
    "    print('Results for {0} comments: Accuracy - {1:.2f}; Precision - {2:.2f}; Recall - {3:.2f}; F1 - {4:.2f}'.format(\n",
    "                                    label, \n",
    "                                    accuracy_score(valid[label], preds), \n",
    "                                    precision_score(valid[label], preds), \n",
    "                                    recall_score(valid[label], preds),\n",
    "                                    f1_score(valid[label], preds)))"
   ]
  },
  {
   "source": [
    "### XGBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE A MODEL FOR EACH CATEGORY\n",
    "for label in labels:\n",
    "    # Create & Fit model\n",
    "    m = XGBClassifier(n_estimators=100,\n",
    "                      scale_pos_weight= sum(train[label]==0) / sum(train[label]==1),\n",
    "                      n_jobs=-1)\n",
    "    m.fit(X_train, train[label])\n",
    "    # Get predictions\n",
    "    preds = m.predict(X_valid)\n",
    "    # Evaluate predictions\n",
    "    print('Results for {0} comments: Accuracy - {1:.2f}; Precision - {2:.2f}; Recall - {3:.2f}; F1 - {4:.2f}'.format(\n",
    "                                    label, \n",
    "                                    accuracy_score(valid[label], preds), \n",
    "                                    precision_score(valid[label], preds), \n",
    "                                    recall_score(valid[label], preds),\n",
    "                                    f1_score(valid[label], preds)))"
   ]
  }
 ]
}